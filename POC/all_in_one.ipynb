{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from pandas) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pypdf in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (5.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pypdf2 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (3.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: cryptography in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (44.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from cryptography) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from cffi>=1.12->cryptography) (2.22)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pikepdf in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (9.4.2)\n",
      "Requirement already satisfied: Pillow>=10.0.1 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from pikepdf) (11.0.0)\n",
      "Requirement already satisfied: Deprecated in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from pikepdf) (1.2.15)\n",
      "Requirement already satisfied: lxml>=4.8 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from pikepdf) (5.3.0)\n",
      "Requirement already satisfied: packaging in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from pikepdf) (24.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from Deprecated->pikepdf) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: streamlit in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (1.41.1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from streamlit) (2.2.0)\n",
      "Requirement already satisfied: packaging<25,>=20 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from streamlit) (11.0.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from streamlit) (5.29.1)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from streamlit) (18.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from streamlit) (13.9.4)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from altair<6,>=4.0->streamlit) (1.18.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit) (2024.12.14)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/usuario-rtd/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install pypdf\n",
    "!pip install pypdf2\n",
    "!pip install cryptography\n",
    "!pip install pikepdf\n",
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasta já existe: ./maps/encrypted/\n",
      "Pasta já existe: ./maps/encrypted/processed\n",
      "Pasta já existe: ./maps/decrypted/\n",
      "Pasta já existe: ./maps/decrypted/processed\n",
      "PDF desbloqueado com sucesso! Salvo em: ./maps/decrypted/decrypted_00c418f7-5eed-4355-bf27-d622a990f0cb.pdf\n",
      "PDF original criptografado movido para: ./maps/encrypted/processed\n",
      "\n",
      "Total de páginas detectadas em 'decrypted_00c418f7-5eed-4355-bf27-d622a990f0cb.pdf': 7\n",
      "\n",
      "PDF 'decrypted_00c418f7-5eed-4355-bf27-d622a990f0cb.pdf' movido para a pasta de processados: maps/decrypted/processed/decrypted_00c418f7-5eed-4355-bf27-d622a990f0cb.pdf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pagina_pdf</th>\n",
       "      <th>nome</th>\n",
       "      <th>nif</th>\n",
       "      <th>mes_mapa</th>\n",
       "      <th>instituicao</th>\n",
       "      <th>divida</th>\n",
       "      <th>litigio</th>\n",
       "      <th>parcela</th>\n",
       "      <th>garantias</th>\n",
       "      <th>num_devedores</th>\n",
       "      <th>prod_financeiro</th>\n",
       "      <th>entrada_incumpr</th>\n",
       "      <th>dat_inicio</th>\n",
       "      <th>dat_fim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>texto_pagina1</td>\n",
       "      <td>PAULO RENATO MACHADO DE SARAIVA CALDEIRA</td>\n",
       "      <td>239581652</td>\n",
       "      <td>janeiro de 2024</td>\n",
       "      <td>COFIDIS (0921)</td>\n",
       "      <td>10 595,44</td>\n",
       "      <td>Não</td>\n",
       "      <td>171,60</td>\n",
       "      <td>8 200,00</td>\n",
       "      <td>1</td>\n",
       "      <td>Crédito automóvel (excluíndo locações financei...</td>\n",
       "      <td>2023-11-02</td>\n",
       "      <td>2019-09-02</td>\n",
       "      <td>2029-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>texto_pagina2</td>\n",
       "      <td>PAULO RENATO MACHADO DE SARAIVA CALDEIRA</td>\n",
       "      <td>239581652</td>\n",
       "      <td>janeiro de 2024</td>\n",
       "      <td>UNIVERSO, IME, S.A. (7500)</td>\n",
       "      <td>1 674,98</td>\n",
       "      <td>Não</td>\n",
       "      <td>322,67</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Cartão de crédito - com período de free-float</td>\n",
       "      <td>2023-08-07</td>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>texto_pagina3</td>\n",
       "      <td>PAULO RENATO MACHADO DE SARAIVA CALDEIRA</td>\n",
       "      <td>239581652</td>\n",
       "      <td>janeiro de 2024</td>\n",
       "      <td>WIZINK BANK, S.A.U. - SUCURSAL EM PORTUGAL (0272)</td>\n",
       "      <td>1 665,94</td>\n",
       "      <td>Não</td>\n",
       "      <td>0,00</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Cartão de crédito - com período de free-float</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>2021-04-29</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>texto_pagina4</td>\n",
       "      <td>PAULO RENATO MACHADO DE SARAIVA CALDEIRA</td>\n",
       "      <td>239581652</td>\n",
       "      <td>janeiro de 2024</td>\n",
       "      <td>BANCO CREDIBOM, SA (0916)</td>\n",
       "      <td>943,98</td>\n",
       "      <td>Não</td>\n",
       "      <td>32,00</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Crédito pessoal</td>\n",
       "      <td>2023-09-11</td>\n",
       "      <td>2021-08-11</td>\n",
       "      <td>2026-04-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>texto_pagina5</td>\n",
       "      <td>PAULO RENATO MACHADO DE SARAIVA CALDEIRA</td>\n",
       "      <td>239581652</td>\n",
       "      <td>janeiro de 2024</td>\n",
       "      <td>BANKINTER CONSUMER FINANCE, E.F.C., SA - SUCUR...</td>\n",
       "      <td>2 135,62</td>\n",
       "      <td>Não</td>\n",
       "      <td>0,00</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Cartão de crédito - com período de free-float</td>\n",
       "      <td>2023-11-20</td>\n",
       "      <td>2022-02-21</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>texto_pagina6</td>\n",
       "      <td>PAULO RENATO MACHADO DE SARAIVA CALDEIRA</td>\n",
       "      <td>239581652</td>\n",
       "      <td>janeiro de 2024</td>\n",
       "      <td>ONEY BANK - SUCURSAL EM PORTUGAL  (0881)</td>\n",
       "      <td>753,75</td>\n",
       "      <td>Não</td>\n",
       "      <td>153,15</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Crédito pessoal</td>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>2023-02-02</td>\n",
       "      <td>2023-12-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pagina_pdf                                      nome        nif  \\\n",
       "0  texto_pagina1  PAULO RENATO MACHADO DE SARAIVA CALDEIRA  239581652   \n",
       "1  texto_pagina2  PAULO RENATO MACHADO DE SARAIVA CALDEIRA  239581652   \n",
       "2  texto_pagina3  PAULO RENATO MACHADO DE SARAIVA CALDEIRA  239581652   \n",
       "3  texto_pagina4  PAULO RENATO MACHADO DE SARAIVA CALDEIRA  239581652   \n",
       "4  texto_pagina5  PAULO RENATO MACHADO DE SARAIVA CALDEIRA  239581652   \n",
       "5  texto_pagina6  PAULO RENATO MACHADO DE SARAIVA CALDEIRA  239581652   \n",
       "\n",
       "          mes_mapa                                        instituicao  \\\n",
       "0  janeiro de 2024                                     COFIDIS (0921)   \n",
       "1  janeiro de 2024                         UNIVERSO, IME, S.A. (7500)   \n",
       "2  janeiro de 2024  WIZINK BANK, S.A.U. - SUCURSAL EM PORTUGAL (0272)   \n",
       "3  janeiro de 2024                          BANCO CREDIBOM, SA (0916)   \n",
       "4  janeiro de 2024  BANKINTER CONSUMER FINANCE, E.F.C., SA - SUCUR...   \n",
       "5  janeiro de 2024           ONEY BANK - SUCURSAL EM PORTUGAL  (0881)   \n",
       "\n",
       "      divida litigio parcela garantias num_devedores  \\\n",
       "0  10 595,44     Não  171,60  8 200,00             1   \n",
       "1   1 674,98     Não  322,67      None             1   \n",
       "2   1 665,94     Não    0,00      None             1   \n",
       "3     943,98     Não   32,00      None             1   \n",
       "4   2 135,62     Não    0,00      None             1   \n",
       "5     753,75     Não  153,15      None             1   \n",
       "\n",
       "                                     prod_financeiro entrada_incumpr  \\\n",
       "0  Crédito automóvel (excluíndo locações financei...      2023-11-02   \n",
       "1      Cartão de crédito - com período de free-float      2023-08-07   \n",
       "2      Cartão de crédito - com período de free-float      2023-08-01   \n",
       "3                                    Crédito pessoal      2023-09-11   \n",
       "4      Cartão de crédito - com período de free-float      2023-11-20   \n",
       "5                                    Crédito pessoal      2023-08-31   \n",
       "\n",
       "   dat_inicio     dat_fim  \n",
       "0  2019-09-02  2029-11-01  \n",
       "1  2020-11-16  9999-12-31  \n",
       "2  2021-04-29  9999-12-31  \n",
       "3  2021-08-11  2026-04-11  \n",
       "4  2022-02-21  9999-12-31  \n",
       "5  2023-02-02  2023-12-29  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pikepdf\n",
    "import re\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Caminhos das pastas\n",
    "source_folder = \"./maps/encrypted/\"\n",
    "processed_folder = os.path.join(source_folder, \"processed\")\n",
    "decrypted_folder = \"./maps/decrypted/\"\n",
    "decrypted_processed_folder = os.path.join(decrypted_folder, \"processed\")\n",
    "\n",
    "# Função para verificar e criar a hierarquia de pastas\n",
    "def ensure_folders_exist():\n",
    "    folders = [source_folder, processed_folder, decrypted_folder, decrypted_processed_folder]\n",
    "    for folder in folders:\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "            print(f\"Pasta criada: {folder}\")\n",
    "        else:\n",
    "            print(f\"Pasta já existe: {folder}\")\n",
    "\n",
    "# Cria a hierarquia de pastas\n",
    "ensure_folders_exist()\n",
    "\n",
    "\n",
    "# Busca o primeiro arquivo PDF na pasta maps\n",
    "pdf_files = [f for f in os.listdir(source_folder) if f.endswith('.pdf')]\n",
    "\n",
    "if not pdf_files:\n",
    "    print(\"Nenhum arquivo PDF encontrado na pasta maps.\")\n",
    "else:\n",
    "    encrypted_pdf_path = os.path.join(source_folder, pdf_files[0])\n",
    "    decrypted_pdf_path = os.path.join(decrypted_folder, f\"decrypted_{pdf_files[0]}\")\n",
    "\n",
    "    try:\n",
    "        # Tenta descriptografar o PDF\n",
    "        with pikepdf.open(encrypted_pdf_path) as pdf:\n",
    "            pdf.save(decrypted_pdf_path)\n",
    "        print(f\"PDF desbloqueado com sucesso! Salvo em: {decrypted_pdf_path}\")\n",
    "\n",
    "        # Move o PDF criptografado para a pasta processed\n",
    "        shutil.move(encrypted_pdf_path, os.path.join(processed_folder, pdf_files[0]))\n",
    "        print(f\"PDF original criptografado movido para: {processed_folder}\")\n",
    "\n",
    "    except pikepdf.PasswordError:\n",
    "        print(f\"O PDF '{pdf_files[0]}' está protegido por senha e não pode ser desbloqueado sem ela.\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Erro: Arquivo não encontrado. Verifique o caminho. {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Paths das pastas\n",
    "input_folder = \"./maps/decrypted\"\n",
    "processed_folder = \"maps/decrypted/processed\"\n",
    "\n",
    "# Verificar se a pasta de processados existe, caso contrário, criá-la\n",
    "os.makedirs(processed_folder, exist_ok=True)\n",
    "\n",
    "# Obter a lista de PDFs na pasta de entrada\n",
    "pdf_files = [file for file in os.listdir(input_folder) if file.lower().endswith(\".pdf\")]\n",
    "\n",
    "if pdf_files:\n",
    "    # Processar cada PDF na pasta\n",
    "    for file_name in pdf_files:\n",
    "        input_pdf_path = os.path.join(input_folder, file_name)\n",
    "        processed_pdf_path = os.path.join(processed_folder, file_name)\n",
    "        \n",
    "        try:\n",
    "            # Inicializar o texto completo para o PDF atual\n",
    "            full_text = \"\"\n",
    "            \n",
    "            # Ler o PDF\n",
    "            reader = PdfReader(input_pdf_path)\n",
    "            \n",
    "            # Iterar sobre as páginas e adicionar os delimitadores\n",
    "            for idx, page in enumerate(reader.pages):\n",
    "                full_text += f\"------------------ PAGINA {idx} ----------------\\n\"\n",
    "                full_text += page.extract_text()\n",
    "            \n",
    "            # Dividir o texto baseado nos delimitadores\n",
    "            paginas = re.split(r\"------------------ PAGINA \\d+ ----------------\", full_text)\n",
    "            paginas = [pagina.strip() for pagina in paginas if pagina.strip()]\n",
    "            \n",
    "            # Exibir a quantidade de páginas úteis detectadas\n",
    "            print(f\"\\nTotal de páginas detectadas em '{file_name}': {len(paginas)}\\n\")\n",
    "            \n",
    "            # Criar dicionário para armazenar o conteúdo das páginas\n",
    "            texto_paginas = {}\n",
    "            for idx, pagina in enumerate(paginas, start=1):\n",
    "                texto_paginas[f\"texto_pagina{idx}\"] = pagina\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Ocorreu um erro ao processar '{file_name}': {e}\")\n",
    "        finally:\n",
    "            # Mover o PDF processado para a pasta de processados\n",
    "            shutil.move(input_pdf_path, processed_pdf_path)\n",
    "            print(f\"PDF '{file_name}' movido para a pasta de processados: {processed_pdf_path}\")\n",
    "else:\n",
    "    print(\"Nenhum PDF encontrado na pasta de entrada.\")\n",
    "\n",
    "\n",
    "\n",
    "# Regexes para capturar os elementos de interesse\n",
    "regexes = {\n",
    "    'nome': re.compile(r'Nome:\\s+(.+)', re.MULTILINE),\n",
    "    'nif': re.compile(r'Nº de Identificação:\\s+(\\d+)'),\n",
    "    'mes_mapa': re.compile(r'Responsabilidades de crédito referentes a\\s+(.+)'),\n",
    "    'instituicao': re.compile(r'Informação comunicada pela instituição:\\s+(.+)'),\n",
    "    'total_em_divida': re.compile(r\"Montantes\\s+Total em dívida\\s+do qual, em incumprimento\\s+([\\d\\s,]+) €\"),\n",
    "    'litigio': re.compile(r'Em litígio judicial\\s+(Sim|Não)'),\n",
    "    'abatido_ativo': re.compile(r'Abatido ao ativo\\s+([\\d\\s,.]+) €'),\n",
    "    'garantias': re.compile(r\"Tipo\\s+Valor\\s+Número\\s+\\d+\\s+([\\d\\s,.]+) €\"),\n",
    "    'num_devedores': re.compile(r\"Nº devedores no contrato\\s+(\\d+)\"),\n",
    "    'prod_financeiro': re.compile(r\"Produto financeiro\\s+(.+?)\\s+Tipo de responsabilidade\"),\n",
    "    'dat_inicio': re.compile(r\"Início\\s+(\\d{4}-\\d{2}-\\d{2})\"),\n",
    "    'dat_fim': re.compile(r\"Fim\\s+(\\d{4}-\\d{2}-\\d{2})\\s+Em litígio judicial\"),\n",
    "    'entrada_incumpr': re.compile(r\"Entrada incumpr\\.\\s+(\\d{4}-\\d{2}-\\d{2})\\s+Tipo\")\n",
    "}\n",
    "\n",
    "# Função para aplicar regex em texto\n",
    "def get_feature(text, regex_string):\n",
    "    match = regexes[regex_string].search(text)\n",
    "    return match.group(1).strip() if match else None\n",
    " \n",
    "# Inicializar lista para armazenar os dados\n",
    "data = []\n",
    "\n",
    "# Iterar sobre as páginas do dicionário texto_paginas\n",
    "for page_number, page_text in texto_paginas.items():\n",
    "    # Extrair informações de cada página usando regex\n",
    "    row = {\n",
    "        'pagina_pdf': page_number,\n",
    "        'nome': get_feature(page_text, 'nome'),\n",
    "        'nif': get_feature(page_text, 'nif'),\n",
    "        'mes_mapa': get_feature(page_text, 'mes_mapa'),\n",
    "        'instituicao': get_feature(page_text, 'instituicao'),\n",
    "        'divida': get_feature(page_text, 'total_em_divida'),\n",
    "        'litigio': get_feature(page_text, 'litigio'),\n",
    "        'parcela': get_feature(page_text, 'abatido_ativo'),\n",
    "        'garantias': get_feature(page_text, 'garantias'),\n",
    "        'num_devedores': get_feature(page_text, 'num_devedores'),\n",
    "        'prod_financeiro': get_feature(page_text, 'prod_financeiro'),\n",
    "        'entrada_incumpr': get_feature(page_text,'entrada_incumpr'),\n",
    "        'dat_inicio': get_feature(page_text, 'dat_inicio'),\n",
    "        'dat_fim': get_feature(page_text, 'dat_fim')\n",
    "    }\n",
    "    # Adicionar os dados ao conjunto\n",
    "    data.append(row)\n",
    "\n",
    "# Criar o DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df.iloc[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasta já existe: ./maps/encrypted/\n",
      "Pasta já existe: ./maps/encrypted/processed\n",
      "Pasta já existe: ./maps/decrypted/\n",
      "Pasta já existe: ./maps/decrypted/processed\n",
      "Pasta já existe: ./maps/f2_senninha/\n",
      "PDF desbloqueado com sucesso! Salvo em: ./maps/decrypted/decrypted_0aec657e-fbae-42b9-8e2a-9c6e38dc6e57.pdf\n",
      "PDF original criptografado movido para: ./maps/encrypted/processed\n",
      "\n",
      "Total de páginas detectadas em 'decrypted_0aec657e-fbae-42b9-8e2a-9c6e38dc6e57.pdf': 0\n",
      "\n",
      "PDF 'decrypted_0aec657e-fbae-42b9-8e2a-9c6e38dc6e57.pdf' movido para a pasta de processados: maps/decrypted/processed/decrypted_0aec657e-fbae-42b9-8e2a-9c6e38dc6e57.pdf\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'divida'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 173\u001b[0m\n\u001b[1;32m    168\u001b[0m df\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m#### TRATAMENTO DE DADOS DO SENNINHA\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# Tratamento da coluna divida\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdivida\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdivida\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)  \u001b[38;5;66;03m# Converte para string\u001b[39;00m\n\u001b[1;32m    174\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdivida\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdivida\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Remove caracteres indesejados e ajusta separadores\u001b[39;00m\n\u001b[1;32m    175\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdivida\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdivida\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Converte para numérico, substituindo erros por NaN\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Documents/mapa_regex_gb_v1/.venv/lib/python3.13/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'divida'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pikepdf\n",
    "\n",
    "# Caminhos das pastas\n",
    "source_folder = \"./maps/encrypted/\"\n",
    "processed_folder = os.path.join(source_folder, \"processed\")\n",
    "decrypted_folder = \"./maps/decrypted/\"\n",
    "decrypted_processed_folder = os.path.join(decrypted_folder, \"processed\")\n",
    "f2_senninha_folder = \"./maps/f2_senninha/\"\n",
    "\n",
    "# Função para verificar e criar a hierarquia de pastas\n",
    "def ensure_folders_exist():\n",
    "    folders = [\n",
    "        source_folder,\n",
    "        processed_folder,\n",
    "        decrypted_folder,\n",
    "        decrypted_processed_folder,\n",
    "        f2_senninha_folder,  # Inclui a nova pasta\n",
    "    ]\n",
    "    for folder in folders:\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "            print(f\"Pasta criada: {folder}\")\n",
    "        else:\n",
    "            print(f\"Pasta já existe: {folder}\")\n",
    "\n",
    "# Cria a hierarquia de pastas\n",
    "ensure_folders_exist()\n",
    "\n",
    "# Busca o primeiro arquivo PDF na pasta maps\n",
    "pdf_files = [f for f in os.listdir(source_folder) if f.endswith('.pdf')]\n",
    "\n",
    "if not pdf_files:\n",
    "    print(\"Nenhum arquivo PDF encontrado na pasta maps.\")\n",
    "else:\n",
    "    encrypted_pdf_path = os.path.join(source_folder, pdf_files[0])\n",
    "    decrypted_pdf_path = os.path.join(decrypted_folder, f\"decrypted_{pdf_files[0]}\")\n",
    "\n",
    "    try:\n",
    "        # Tenta descriptografar o PDF\n",
    "        with pikepdf.open(encrypted_pdf_path) as pdf:\n",
    "            pdf.save(decrypted_pdf_path)\n",
    "        print(f\"PDF desbloqueado com sucesso! Salvo em: {decrypted_pdf_path}\")\n",
    "\n",
    "        # Move o PDF criptografado para a pasta processed\n",
    "        shutil.move(encrypted_pdf_path, os.path.join(processed_folder, pdf_files[0]))\n",
    "        print(f\"PDF original criptografado movido para: {processed_folder}\")\n",
    "\n",
    "    except pikepdf.PasswordError:\n",
    "        print(f\"O PDF '{pdf_files[0]}' está protegido por senha e não pode ser desbloqueado sem ela.\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Erro: Arquivo não encontrado. Verifique o caminho. {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro: {e}\")\n",
    "\n",
    "\n",
    "from PyPDF2 import PdfReader\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "# Paths das pastas\n",
    "input_folder = \"./maps/decrypted\"\n",
    "processed_folder = \"maps/decrypted/processed\"\n",
    "\n",
    "# Verificar se a pasta de processados existe, caso contrário, criá-la\n",
    "os.makedirs(processed_folder, exist_ok=True)\n",
    "\n",
    "# Obter a lista de PDFs na pasta de entrada\n",
    "pdf_files = [file for file in os.listdir(input_folder) if file.lower().endswith(\".pdf\")]\n",
    "\n",
    "if pdf_files:\n",
    "    # Processar cada PDF na pasta\n",
    "    for file_name in pdf_files:\n",
    "        input_pdf_path = os.path.join(input_folder, file_name)\n",
    "        processed_pdf_path = os.path.join(processed_folder, file_name)\n",
    "        \n",
    "        try:\n",
    "            # Inicializar o texto completo para o PDF atual\n",
    "            full_text = \"\"\n",
    "            \n",
    "            # Ler o PDF\n",
    "            reader = PdfReader(input_pdf_path)\n",
    "            \n",
    "            # Iterar sobre as páginas e adicionar os delimitadores\n",
    "            for idx, page in enumerate(reader.pages):\n",
    "                full_text += f\"------------------ PAGINA {idx} ----------------\\n\"\n",
    "                full_text += page.extract_text()\n",
    "            \n",
    "            # Dividir o texto baseado nos delimitadores\n",
    "            paginas = re.split(r\"------------------ PAGINA \\d+ ----------------\", full_text)\n",
    "            paginas = [pagina.strip() for pagina in paginas if pagina.strip()]\n",
    "            \n",
    "            # Exibir a quantidade de páginas úteis detectadas\n",
    "            print(f\"\\nTotal de páginas detectadas em '{file_name}': {len(paginas)}\\n\")\n",
    "            \n",
    "            # Criar dicionário para armazenar o conteúdo das páginas\n",
    "            texto_paginas = {}\n",
    "            for idx, pagina in enumerate(paginas, start=1):\n",
    "                texto_paginas[f\"texto_pagina{idx}\"] = pagina\n",
    "            \n",
    "            # Você pode processar o dicionário `texto_paginas` aqui, se necessário\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Ocorreu um erro ao processar '{file_name}': {e}\")\n",
    "        finally:\n",
    "            # Mover o PDF processado para a pasta de processados\n",
    "            shutil.move(input_pdf_path, processed_pdf_path)\n",
    "            print(f\"PDF '{file_name}' movido para a pasta de processados: {processed_pdf_path}\")\n",
    "else:\n",
    "    print(\"Nenhum PDF encontrado na pasta de entrada.\")\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Regexes para capturar os elementos de interesse\n",
    "regexes = {\n",
    "    'nome': re.compile(r'Nome:\\s+(.+)', re.MULTILINE),\n",
    "    'nif': re.compile(r'Nº de Identificação:\\s+(\\d+)'),\n",
    "    'mes_mapa': re.compile(r'Responsabilidades de crédito referentes a\\s+(.+)'),\n",
    "    'instituicao': re.compile(r'Informação comunicada pela instituição:\\s+(.+)'),\n",
    "    'total_em_divida': re.compile(r\"Montantes\\s+Total em dívida\\s+do qual, em incumprimento\\s+([\\d\\s,]+) €\"),\n",
    "    'litigio': re.compile(r'Em litígio judicial\\s+(Sim|Não)'),\n",
    "    'abatido_ativo': re.compile(r'Abatido ao ativo\\s+([\\d\\s,.]+) €'),\n",
    "    'garantias': re.compile(r\"Tipo\\s+Valor\\s+Número\\s+\\d+\\s+([\\d\\s,.]+) €\"),\n",
    "    'num_devedores': re.compile(r\"Nº devedores no contrato\\s+(\\d+)\"),\n",
    "    'prod_financeiro': re.compile(r\"Produto financeiro\\s+(.+?)\\s+Tipo de responsabilidade\"),\n",
    "    'dat_inicio': re.compile(r\"Início\\s+(\\d{4}-\\d{2}-\\d{2})\"),\n",
    "    'dat_fim': re.compile(r\"Fim\\s+(\\d{4}-\\d{2}-\\d{2})\\s+Em litígio judicial\"),\n",
    "    'entrada_incumpr': re.compile(r\"Entrada incumpr\\.\\s+(\\d{4}-\\d{2}-\\d{2})\\s+Tipo\")\n",
    "}\n",
    "\n",
    "# Função para aplicar regex em texto\n",
    "def get_feature(text, regex_string):\n",
    "    match = regexes[regex_string].search(text)\n",
    "    return match.group(1).strip() if match else None\n",
    " \n",
    "# Inicializar lista para armazenar os dados\n",
    "data = []\n",
    "\n",
    "# Iterar sobre as páginas do dicionário texto_paginas\n",
    "for page_number, page_text in texto_paginas.items():\n",
    "    # Extrair informações de cada página usando regex\n",
    "    row = {\n",
    "        'pagina_pdf': page_number,\n",
    "        'nome': get_feature(page_text, 'nome'),\n",
    "        'nif': get_feature(page_text, 'nif'),\n",
    "        'mes_mapa': get_feature(page_text, 'mes_mapa'),\n",
    "        'instituicao': get_feature(page_text, 'instituicao'),\n",
    "        'divida': get_feature(page_text, 'total_em_divida'),\n",
    "        'litigio': get_feature(page_text, 'litigio'),\n",
    "        'parcela': get_feature(page_text, 'abatido_ativo'),\n",
    "        'garantias': get_feature(page_text, 'garantias'),\n",
    "        'num_devedores': get_feature(page_text, 'num_devedores'),\n",
    "        'prod_financeiro': get_feature(page_text, 'prod_financeiro'),\n",
    "        'entrada_incumpr': get_feature(page_text,'entrada_incumpr'),\n",
    "        'dat_inicio': get_feature(page_text, 'dat_inicio'),\n",
    "        'dat_fim': get_feature(page_text, 'dat_fim')\n",
    "    }\n",
    "    # Adicionar os dados ao conjunto\n",
    "    data.append(row)\n",
    "\n",
    "# Criar o DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df.iloc[:-1]\n",
    "\n",
    "df\n",
    "\n",
    "#### TRATAMENTO DE DADOS DO SENNINHA\n",
    "\n",
    "# Tratamento da coluna divida\n",
    "df['divida'] = df['divida'].astype(str)  # Converte para string\n",
    "df['divida'] = df['divida'].str.replace(' ', '').str.replace(',', '.')  # Remove caracteres indesejados e ajusta separadores\n",
    "df['divida'] = pd.to_numeric(df['divida'], errors='coerce')  # Converte para numérico, substituindo erros por NaN\n",
    "df['divida'] = df['divida'].fillna(0.0)  # Substitui NaN por 0.0\n",
    "\n",
    "# Tratamento da coluna parcela\n",
    "df['parcela'] = df['parcela'].astype(str)  # Converte para string\n",
    "df['parcela'] = df['parcela'].str.replace(' ', '').str.replace(',', '.')  # Remove caracteres indesejados e ajusta separadores\n",
    "df['parcela'] = pd.to_numeric(df['parcela'], errors='coerce')  # Converte para numérico, substituindo erros por NaN\n",
    "df['parcela'] = df['parcela'].fillna(0.0)  # Substitui NaN por 0.0\n",
    "\n",
    "# Tratamento da coluna garantias\n",
    "df['garantias'] = df['garantias'].astype(str)  # Converte para string\n",
    "df['garantias'] = df['garantias'].str.replace(' ', '').str.replace(',', '.')  # Remove caracteres indesejados e ajusta separadores\n",
    "df['garantias'] = pd.to_numeric(df['garantias'], errors='coerce')  # Converte para numérico, substituindo erros por NaN\n",
    "df['garantias'] = df['garantias'].fillna(0.0)  # Substitui NaN por 0.0\n",
    "\n",
    "df\n",
    "\n",
    "#PERFILADOR SENNINHA\n",
    "\n",
    "# Aplicando o segundo filtro onde a coluna \"litigio\" é igual a \"Não\"\n",
    "df_litigio= df[df[\"litigio\"] == \"Não\"]\n",
    "\n",
    "# Lista de opções para filtro\n",
    "opcoes_prod_financeiro = [\n",
    "    \"Cartão de crédito - sem período de free-float\",\n",
    "    \"Cartão de crédito - com período de free-float\",\n",
    "    \"Crédito automóvel (excluíndo locações financeiras)\",\n",
    "    \"Crédito pessoal\",\n",
    "    \"Crédito renovável - Linha de crédito\",\n",
    "    \"Cartão de crédito\",\n",
    "    \"Outros créditos\",\n",
    "    \"Ultrapassagens de crédito\",\n",
    "    \"Crédito renovável - conta corrente bancária\",\n",
    "    \"Facilidades de descoberto\",\n",
    "    \"Cartão de crédito - cartão de débito diferido\"\n",
    "]\n",
    "\n",
    "# Aplicando o primeiro filtro onde a coluna \"produtos financeiros\" é igual aos prod_financeiros que perfilam\n",
    "df_prod_fin = df_litigio[df_litigio[\"prod_financeiro\"].isin(opcoes_prod_financeiro)]\n",
    "\n",
    "# Aplicando o segundo filtro onde a coluna \"litigio\" é igual a \"Não\"\n",
    "df_prod_fin = df_prod_fin[df_prod_fin[\"litigio\"] == \"Não\"]\n",
    "\n",
    "# Aplicado o terceiro filtro onde a coluna \"garantias\" é menor ou igual a 0.0\n",
    "df_prod_fin = df_prod_fin[df_prod_fin[\"garantias\"] <= 0]\n",
    "\n",
    "\n",
    "df_perfilados_agg = (\n",
    "    df_prod_fin.groupby(\"nif\", as_index=False)\n",
    "    .agg({\n",
    "        \"nome\": \"first\",\n",
    "        \"mes_mapa\": \"first\",\n",
    "        \"litigio\": \"first\",\n",
    "        \"divida\": \"sum\",\n",
    "        \"garantias\": \"sum\"\n",
    "    })\n",
    ")\n",
    "\n",
    "df_perfilados_agg\n",
    "\n",
    "def controle_fluxo(df_perfilados_agg, processed_pdf_path):\n",
    "    \"\"\"\n",
    "    Verifica se o valor da coluna 'divida' em df_perfilados_agg (registro único) é maior ou igual a 6000.\n",
    "    Se for, copia o arquivo especificado em processed_pdf_path para o diretório de destino.\n",
    "\n",
    "    Args:\n",
    "        df_perfilados_agg (DataFrame): DataFrame contendo a coluna 'divida' com apenas um registro.\n",
    "        processed_pdf_path (str): Caminho completo do arquivo a ser copiado.\n",
    "    \"\"\"\n",
    "    # Diretório de destino\n",
    "    destination_dir = \"maps/f2_senninha\"\n",
    "\n",
    "    # Verifica se o destino existe, caso contrário, cria-o\n",
    "    if not os.path.exists(destination_dir):\n",
    "        os.makedirs(destination_dir)\n",
    "\n",
    "    # Verifica se o valor de 'divida' atende à condição\n",
    "    if df_perfilados_agg.loc[0, \"divida\"] >= 6000:\n",
    "        # Extrai o nome do arquivo do caminho fornecido\n",
    "        file_name = os.path.basename(processed_pdf_path)\n",
    "        destination_path = os.path.join(destination_dir, file_name)\n",
    "\n",
    "        # Verifica se o arquivo de origem existe e realiza a cópia\n",
    "        if os.path.exists(processed_pdf_path):\n",
    "            shutil.copy(processed_pdf_path, destination_path)\n",
    "            print(f\"Arquivo {file_name} copiado para {destination_dir}.\")\n",
    "        else:\n",
    "            print(f\"Arquivo {processed_pdf_path} não encontrado.\")\n",
    "    else:\n",
    "        print(\"A dívida é menor que 6000. Nenhuma ação realizada.\")\n",
    "\n",
    "\n",
    "controle_fluxo(df_perfilados_agg, processed_pdf_path)\n",
    "\n",
    "df_perfilados_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEVELOP PERFILADOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         nif                               nome         mes_mapa litigio  \\\n",
       " 0  271878061  FABIO JOSE ROSA DOS SANTOS CATITA  janeiro de 2024     Não   \n",
       " \n",
       "     divida  garantias  \n",
       " 0  4127.73        0.0  ,\n",
       " 'decrypted_09f6484e-1c43-472c-8f8d-9e4d69581026.pdf')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PERFILADOR SENNINHA \n",
    "\n",
    "# Aplicando o segundo filtro onde a coluna \"litigio\" é igual a \"Não\"\n",
    "df_litigio= df[df[\"litigio\"] == \"Não\"]\n",
    "\n",
    "# Lista de opções para filtro\n",
    "opcoes_prod_financeiro = [\n",
    "    \"Cartão de crédito - sem período de free-float\",\n",
    "    \"Cartão de crédito - com período de free-float\",\n",
    "    \"Crédito automóvel (excluíndo locações financeiras)\",\n",
    "    \"Crédito pessoal\",\n",
    "    \"Crédito renovável - Linha de crédito\",\n",
    "    \"Cartão de crédito\",\n",
    "    \"Outros créditos\",\n",
    "    \"Ultrapassagens de crédito\",\n",
    "    \"Crédito renovável - conta corrente bancária\",\n",
    "    \"Facilidades de descoberto\",\n",
    "    \"Cartão de crédito - cartão de débito diferido\"\n",
    "]\n",
    "\n",
    "# Aplicando o primeiro filtro onde a coluna \"produtos financeiros\" é igual aos prod_financeiros que perfilam\n",
    "df_prod_fin = df_litigio[df_litigio[\"prod_financeiro\"].isin(opcoes_prod_financeiro)]\n",
    "\n",
    "# Aplicando o segundo filtro onde a coluna \"litigio\" é igual a \"Não\"\n",
    "df_prod_fin = df_prod_fin[df_prod_fin[\"litigio\"] == \"Não\"]\n",
    "\n",
    "# Aplicado o terceiro filtro onde a coluna \"garantias\" é menor ou igual a 0.0\n",
    "df_prod_fin = df_prod_fin[df_prod_fin[\"garantias\"] <= 0]\n",
    "\n",
    "# somando dividas perfiladas\n",
    "df_perfilados_agg = (\n",
    "    df_prod_fin.groupby(\"nif\", as_index=False)\n",
    "    .agg({\n",
    "        \"nome\": \"first\",\n",
    "        \"mes_mapa\": \"first\",\n",
    "        \"litigio\": \"first\",\n",
    "        \"divida\": \"sum\",\n",
    "        \"garantias\": \"sum\"\n",
    "    })\n",
    ")\n",
    "\n",
    "df_perfilados_agg, file_name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
