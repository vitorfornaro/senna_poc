{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/vitorfornaro/Documents/Senna-Project/venv/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/vitorfornaro/Documents/Senna-Project/venv/lib/python3.12/site-packages (from pandas) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/vitorfornaro/Documents/Senna-Project/venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/vitorfornaro/Documents/Senna-Project/venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/vitorfornaro/Documents/Senna-Project/venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/vitorfornaro/Documents/Senna-Project/venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: pypdf in /Users/vitorfornaro/Documents/Senna-Project/venv/lib/python3.12/site-packages (5.4.0)\n",
      "Requirement already satisfied: pypdf2 in /Users/vitorfornaro/Documents/Senna-Project/venv/lib/python3.12/site-packages (3.0.1)\n",
      "Requirement already satisfied: cryptography in /Users/vitorfornaro/Documents/Senna-Project/venv/lib/python3.12/site-packages (44.0.3)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/vitorfornaro/Documents/Senna-Project/venv/lib/python3.12/site-packages (from cryptography) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /Users/vitorfornaro/Documents/Senna-Project/venv/lib/python3.12/site-packages (from cffi>=1.12->cryptography) (2.22)\n",
      "Requirement already satisfied: pikepdf in /Users/vitorfornaro/Documents/Senna-Project/venv/lib/python3.12/site-packages (9.7.0)\n",
      "Requirement already satisfied: Pillow>=10.0.1 in /Users/vitorfornaro/Documents/Senna-Project/venv/lib/python3.12/site-packages (from pikepdf) (11.2.1)\n",
      "Requirement already satisfied: Deprecated in /Users/vitorfornaro/Documents/Senna-Project/venv/lib/python3.12/site-packages (from pikepdf) (1.2.18)\n",
      "Requirement already satisfied: lxml>=4.8 in /Users/vitorfornaro/Documents/Senna-Project/venv/lib/python3.12/site-packages (from pikepdf) (5.4.0)\n",
      "Requirement already satisfied: packaging in /Users/vitorfornaro/Documents/Senna-Project/venv/lib/python3.12/site-packages (from pikepdf) (24.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/vitorfornaro/Documents/Senna-Project/venv/lib/python3.12/site-packages (from Deprecated->pikepdf) (1.17.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install pypdf\n",
    "!pip install pypdf2\n",
    "!pip install cryptography\n",
    "!pip install pikepdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasta já existe: ./maps/encrypted/\n",
      "Pasta já existe: ./maps/encrypted/processed\n",
      "Pasta já existe: ./maps/decrypted/\n",
      "Pasta já existe: ./maps/decrypted/processed\n",
      "PDF desbloqueado com sucesso! Salvo em: ./maps/decrypted/decrypted_4BB0E92DEBBB7F11.pdf\n",
      "PDF original criptografado movido para: ./maps/encrypted/processed\n",
      "\n",
      "Total de páginas detectadas em 'decrypted_4BB0E92DEBBB7F11.pdf': 7\n",
      "\n",
      "PDF 'decrypted_4BB0E92DEBBB7F11.pdf' movido para a pasta de processados: maps/decrypted/processed/decrypted_4BB0E92DEBBB7F11.pdf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pagina_pdf</th>\n",
       "      <th>nome</th>\n",
       "      <th>nif</th>\n",
       "      <th>mes_mapa</th>\n",
       "      <th>instituicao</th>\n",
       "      <th>divida</th>\n",
       "      <th>litigio</th>\n",
       "      <th>parcela</th>\n",
       "      <th>garantias</th>\n",
       "      <th>num_devedores</th>\n",
       "      <th>prod_financeiro</th>\n",
       "      <th>entrada_incumpr</th>\n",
       "      <th>dat_inicio</th>\n",
       "      <th>dat_fim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>texto_pagina1</td>\n",
       "      <td>INES BOTAS LEAL</td>\n",
       "      <td>208484493</td>\n",
       "      <td>julho de 2023</td>\n",
       "      <td>BANCO PRIMUS, SA (0246)</td>\n",
       "      <td>4 823,77</td>\n",
       "      <td>Não</td>\n",
       "      <td>92,32</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Crédito pessoal</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-11-14</td>\n",
       "      <td>2029-12-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>texto_pagina2</td>\n",
       "      <td>INES BOTAS LEAL</td>\n",
       "      <td>208484493</td>\n",
       "      <td>julho de 2023</td>\n",
       "      <td>BANCO CREDIBOM, SA (0916)</td>\n",
       "      <td>4 954,46</td>\n",
       "      <td>Não</td>\n",
       "      <td>85,24</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Crédito pessoal</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-11-10</td>\n",
       "      <td>2029-11-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>texto_pagina3</td>\n",
       "      <td>INES BOTAS LEAL</td>\n",
       "      <td>208484493</td>\n",
       "      <td>julho de 2023</td>\n",
       "      <td>UNICRE - INSTITUIÇÃO FINANCEIRA DE CRÉDITO, S....</td>\n",
       "      <td>2 893,32</td>\n",
       "      <td>Não</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Cartão de crédito - com período de free-float</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>texto_pagina4</td>\n",
       "      <td>INES BOTAS LEAL</td>\n",
       "      <td>208484493</td>\n",
       "      <td>julho de 2023</td>\n",
       "      <td>WIZINK BANK, S.A.U. - SUCURSAL EM PORTUGAL (0272)</td>\n",
       "      <td>1 528,54</td>\n",
       "      <td>Não</td>\n",
       "      <td>0,00</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Cartão de crédito - com período de free-float</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-03-21</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>texto_pagina5</td>\n",
       "      <td>INES BOTAS LEAL</td>\n",
       "      <td>208484493</td>\n",
       "      <td>julho de 2023</td>\n",
       "      <td>UNIVERSO, IME, S.A. (7500)</td>\n",
       "      <td>749,54</td>\n",
       "      <td>Não</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Cartão de crédito - com período de free-float</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-07-05</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>texto_pagina6</td>\n",
       "      <td>INES BOTAS LEAL</td>\n",
       "      <td>208484493</td>\n",
       "      <td>julho de 2023</td>\n",
       "      <td>ONEY BANK - SUCURSAL EM PORTUGAL  (0881)</td>\n",
       "      <td>1 513,37</td>\n",
       "      <td>Não</td>\n",
       "      <td>0,00</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Cartão de crédito - com período de free-float</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-07-08</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pagina_pdf             nome        nif       mes_mapa  \\\n",
       "0  texto_pagina1  INES BOTAS LEAL  208484493  julho de 2023   \n",
       "1  texto_pagina2  INES BOTAS LEAL  208484493  julho de 2023   \n",
       "2  texto_pagina3  INES BOTAS LEAL  208484493  julho de 2023   \n",
       "3  texto_pagina4  INES BOTAS LEAL  208484493  julho de 2023   \n",
       "4  texto_pagina5  INES BOTAS LEAL  208484493  julho de 2023   \n",
       "5  texto_pagina6  INES BOTAS LEAL  208484493  julho de 2023   \n",
       "\n",
       "                                         instituicao    divida litigio  \\\n",
       "0                            BANCO PRIMUS, SA (0246)  4 823,77     Não   \n",
       "1                          BANCO CREDIBOM, SA (0916)  4 954,46     Não   \n",
       "2  UNICRE - INSTITUIÇÃO FINANCEIRA DE CRÉDITO, S....  2 893,32     Não   \n",
       "3  WIZINK BANK, S.A.U. - SUCURSAL EM PORTUGAL (0272)  1 528,54     Não   \n",
       "4                         UNIVERSO, IME, S.A. (7500)    749,54     Não   \n",
       "5           ONEY BANK - SUCURSAL EM PORTUGAL  (0881)  1 513,37     Não   \n",
       "\n",
       "  parcela garantias num_devedores  \\\n",
       "0   92,32      None             1   \n",
       "1   85,24      None             1   \n",
       "2    None      None             1   \n",
       "3    0,00      None             1   \n",
       "4    None      None             1   \n",
       "5    0,00      None             1   \n",
       "\n",
       "                                 prod_financeiro entrada_incumpr  dat_inicio  \\\n",
       "0                                Crédito pessoal            None  2022-11-14   \n",
       "1                                Crédito pessoal            None  2022-11-10   \n",
       "2  Cartão de crédito - com período de free-float            None  2023-03-31   \n",
       "3  Cartão de crédito - com período de free-float            None  2023-03-21   \n",
       "4  Cartão de crédito - com período de free-float            None  2023-07-05   \n",
       "5  Cartão de crédito - com período de free-float            None  2023-07-08   \n",
       "\n",
       "      dat_fim  \n",
       "0  2029-12-05  \n",
       "1  2029-11-23  \n",
       "2  9999-12-31  \n",
       "3  9999-12-31  \n",
       "4  9999-12-31  \n",
       "5  9999-12-31  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pikepdf\n",
    "import re\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Caminhos das pastas\n",
    "source_folder = \"./maps/encrypted/\"\n",
    "processed_folder = os.path.join(source_folder, \"processed\")\n",
    "decrypted_folder = \"./maps/decrypted/\"\n",
    "decrypted_processed_folder = os.path.join(decrypted_folder, \"processed\")\n",
    "\n",
    "# Função para verificar e criar a hierarquia de pastas\n",
    "def ensure_folders_exist():\n",
    "    folders = [source_folder, processed_folder, decrypted_folder, decrypted_processed_folder]\n",
    "    for folder in folders:\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "            print(f\"Pasta criada: {folder}\")\n",
    "        else:\n",
    "            print(f\"Pasta já existe: {folder}\")\n",
    "\n",
    "# Cria a hierarquia de pastas\n",
    "ensure_folders_exist()\n",
    "\n",
    "\n",
    "# Busca o primeiro arquivo PDF na pasta maps\n",
    "pdf_files = [f for f in os.listdir(source_folder) if f.endswith('.pdf')]\n",
    "\n",
    "if not pdf_files:\n",
    "    print(\"Nenhum arquivo PDF encontrado na pasta maps.\")\n",
    "else:\n",
    "    encrypted_pdf_path = os.path.join(source_folder, pdf_files[0])\n",
    "    decrypted_pdf_path = os.path.join(decrypted_folder, f\"decrypted_{pdf_files[0]}\")\n",
    "\n",
    "    try:\n",
    "        # Tenta descriptografar o PDF\n",
    "        with pikepdf.open(encrypted_pdf_path) as pdf:\n",
    "            pdf.save(decrypted_pdf_path)\n",
    "        print(f\"PDF desbloqueado com sucesso! Salvo em: {decrypted_pdf_path}\")\n",
    "\n",
    "        # Move o PDF criptografado para a pasta processed\n",
    "        shutil.move(encrypted_pdf_path, os.path.join(processed_folder, pdf_files[0]))\n",
    "        print(f\"PDF original criptografado movido para: {processed_folder}\")\n",
    "\n",
    "    except pikepdf.PasswordError:\n",
    "        print(f\"O PDF '{pdf_files[0]}' está protegido por senha e não pode ser desbloqueado sem ela.\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Erro: Arquivo não encontrado. Verifique o caminho. {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Paths das pastas\n",
    "input_folder = \"./maps/decrypted\"\n",
    "processed_folder = \"maps/decrypted/processed\"\n",
    "\n",
    "# Verificar se a pasta de processados existe, caso contrário, criá-la\n",
    "os.makedirs(processed_folder, exist_ok=True)\n",
    "\n",
    "# Obter a lista de PDFs na pasta de entrada\n",
    "pdf_files = [file for file in os.listdir(input_folder) if file.lower().endswith(\".pdf\")]\n",
    "\n",
    "if pdf_files:\n",
    "    # Processar cada PDF na pasta\n",
    "    for file_name in pdf_files:\n",
    "        input_pdf_path = os.path.join(input_folder, file_name)\n",
    "        processed_pdf_path = os.path.join(processed_folder, file_name)\n",
    "        \n",
    "        try:\n",
    "            # Inicializar o texto completo para o PDF atual\n",
    "            full_text = \"\"\n",
    "            \n",
    "            # Ler o PDF\n",
    "            reader = PdfReader(input_pdf_path)\n",
    "            \n",
    "            # Iterar sobre as páginas e adicionar os delimitadores\n",
    "            for idx, page in enumerate(reader.pages):\n",
    "                full_text += f\"------------------ PAGINA {idx} ----------------\\n\"\n",
    "                full_text += page.extract_text()\n",
    "            \n",
    "            # Dividir o texto baseado nos delimitadores\n",
    "            paginas = re.split(r\"------------------ PAGINA \\d+ ----------------\", full_text)\n",
    "            paginas = [pagina.strip() for pagina in paginas if pagina.strip()]\n",
    "            \n",
    "            # Exibir a quantidade de páginas úteis detectadas\n",
    "            print(f\"\\nTotal de páginas detectadas em '{file_name}': {len(paginas)}\\n\")\n",
    "            \n",
    "            # Criar dicionário para armazenar o conteúdo das páginas\n",
    "            texto_paginas = {}\n",
    "            for idx, pagina in enumerate(paginas, start=1):\n",
    "                texto_paginas[f\"texto_pagina{idx}\"] = pagina\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Ocorreu um erro ao processar '{file_name}': {e}\")\n",
    "        finally:\n",
    "            # Mover o PDF processado para a pasta de processados\n",
    "            shutil.move(input_pdf_path, processed_pdf_path)\n",
    "            print(f\"PDF '{file_name}' movido para a pasta de processados: {processed_pdf_path}\")\n",
    "else:\n",
    "    print(\"Nenhum PDF encontrado na pasta de entrada.\")\n",
    "\n",
    "\n",
    "\n",
    "# Regexes para capturar os elementos de interesse\n",
    "regexes = {\n",
    "    'nome': re.compile(r'Nome:\\s+(.+)', re.MULTILINE),\n",
    "    'nif': re.compile(r'Nº de Identificação:\\s+(\\d+)'),\n",
    "    'mes_mapa': re.compile(r'Responsabilidades de crédito referentes a\\s+(.+)'),\n",
    "    'instituicao': re.compile(r'Informação comunicada pela instituição:\\s+(.+)'),\n",
    "    'total_em_divida': re.compile(r\"Montantes\\s+Total em dívida\\s+do qual, em incumprimento\\s+([\\d\\s,]+) €\"),\n",
    "    'litigio': re.compile(r'Em litígio judicial\\s+(Sim|Não)'),\n",
    "    'abatido_ativo': re.compile(r'Abatido ao ativo\\s+([\\d\\s,.]+) €'),\n",
    "    'garantias': re.compile(r\"Tipo\\s+Valor\\s+Número\\s+\\d+\\s+([\\d\\s,.]+) €\"),\n",
    "    'num_devedores': re.compile(r\"Nº devedores no contrato\\s+(\\d+)\"),\n",
    "    'prod_financeiro': re.compile(r\"Produto financeiro\\s+(.+?)\\s+Tipo de responsabilidade\"),\n",
    "    'dat_inicio': re.compile(r\"Início\\s+(\\d{4}-\\d{2}-\\d{2})\"),\n",
    "    'dat_fim': re.compile(r\"Fim\\s+(\\d{4}-\\d{2}-\\d{2})\\s+Em litígio judicial\"),\n",
    "    'entrada_incumpr': re.compile(r\"Entrada incumpr\\.\\s+(\\d{4}-\\d{2}-\\d{2})\\s+Tipo\")\n",
    "}\n",
    "\n",
    "# Função para aplicar regex em texto\n",
    "def get_feature(text, regex_string):\n",
    "    match = regexes[regex_string].search(text)\n",
    "    return match.group(1).strip() if match else None\n",
    " \n",
    "# Inicializar lista para armazenar os dados\n",
    "data = []\n",
    "\n",
    "# Iterar sobre as páginas do dicionário texto_paginas\n",
    "for page_number, page_text in texto_paginas.items():\n",
    "    # Extrair informações de cada página usando regex\n",
    "    row = {\n",
    "        'pagina_pdf': page_number,\n",
    "        'nome': get_feature(page_text, 'nome'),\n",
    "        'nif': get_feature(page_text, 'nif'),\n",
    "        'mes_mapa': get_feature(page_text, 'mes_mapa'),\n",
    "        'instituicao': get_feature(page_text, 'instituicao'),\n",
    "        'divida': get_feature(page_text, 'total_em_divida'),\n",
    "        'litigio': get_feature(page_text, 'litigio'),\n",
    "        'parcela': get_feature(page_text, 'abatido_ativo'),\n",
    "        'garantias': get_feature(page_text, 'garantias'),\n",
    "        'num_devedores': get_feature(page_text, 'num_devedores'),\n",
    "        'prod_financeiro': get_feature(page_text, 'prod_financeiro'),\n",
    "        'entrada_incumpr': get_feature(page_text,'entrada_incumpr'),\n",
    "        'dat_inicio': get_feature(page_text, 'dat_inicio'),\n",
    "        'dat_fim': get_feature(page_text, 'dat_fim')\n",
    "    }\n",
    "    # Adicionar os dados ao conjunto\n",
    "    data.append(row)\n",
    "\n",
    "# Criar o DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df.iloc[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasta já existe: ./maps/encrypted/\n",
      "Pasta já existe: ./maps/encrypted/processed\n",
      "Pasta já existe: ./maps/decrypted/\n",
      "Pasta já existe: ./maps/decrypted/processed\n",
      "Pasta criada: ./maps/f2_senninha/\n",
      "Nenhum arquivo PDF encontrado na pasta maps.\n",
      "Nenhum PDF encontrado na pasta de entrada.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'texto_paginas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 143\u001b[39m\n\u001b[32m    140\u001b[39m data = []\n\u001b[32m    142\u001b[39m \u001b[38;5;66;03m# Iterar sobre as páginas do dicionário texto_paginas\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m page_number, page_text \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtexto_paginas\u001b[49m.items():\n\u001b[32m    144\u001b[39m     \u001b[38;5;66;03m# Extrair informações de cada página usando regex\u001b[39;00m\n\u001b[32m    145\u001b[39m     row = {\n\u001b[32m    146\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mpagina_pdf\u001b[39m\u001b[33m'\u001b[39m: page_number,\n\u001b[32m    147\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mnome\u001b[39m\u001b[33m'\u001b[39m: get_feature(page_text, \u001b[33m'\u001b[39m\u001b[33mnome\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m    159\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mdat_fim\u001b[39m\u001b[33m'\u001b[39m: get_feature(page_text, \u001b[33m'\u001b[39m\u001b[33mdat_fim\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    160\u001b[39m     }\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# Adicionar os dados ao conjunto\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'texto_paginas' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pikepdf\n",
    "\n",
    "# Caminhos das pastas\n",
    "source_folder = \"./maps/encrypted/\"\n",
    "processed_folder = os.path.join(source_folder, \"processed\")\n",
    "decrypted_folder = \"./maps/decrypted/\"\n",
    "decrypted_processed_folder = os.path.join(decrypted_folder, \"processed\")\n",
    "f2_senninha_folder = \"./maps/f2_senninha/\"\n",
    "\n",
    "# Função para verificar e criar a hierarquia de pastas\n",
    "def ensure_folders_exist():\n",
    "    folders = [\n",
    "        source_folder,\n",
    "        processed_folder,\n",
    "        decrypted_folder,\n",
    "        decrypted_processed_folder,\n",
    "        f2_senninha_folder,  # Inclui a nova pasta\n",
    "    ]\n",
    "    for folder in folders:\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "            print(f\"Pasta criada: {folder}\")\n",
    "        else:\n",
    "            print(f\"Pasta já existe: {folder}\")\n",
    "\n",
    "# Cria a hierarquia de pastas\n",
    "ensure_folders_exist()\n",
    "\n",
    "# Busca o primeiro arquivo PDF na pasta maps\n",
    "pdf_files = [f for f in os.listdir(source_folder) if f.endswith('.pdf')]\n",
    "\n",
    "if not pdf_files:\n",
    "    print(\"Nenhum arquivo PDF encontrado na pasta maps.\")\n",
    "else:\n",
    "    encrypted_pdf_path = os.path.join(source_folder, pdf_files[0])\n",
    "    decrypted_pdf_path = os.path.join(decrypted_folder, f\"decrypted_{pdf_files[0]}\")\n",
    "\n",
    "    try:\n",
    "        # Tenta descriptografar o PDF\n",
    "        with pikepdf.open(encrypted_pdf_path) as pdf:\n",
    "            pdf.save(decrypted_pdf_path)\n",
    "        print(f\"PDF desbloqueado com sucesso! Salvo em: {decrypted_pdf_path}\")\n",
    "\n",
    "        # Move o PDF criptografado para a pasta processed\n",
    "        shutil.move(encrypted_pdf_path, os.path.join(processed_folder, pdf_files[0]))\n",
    "        print(f\"PDF original criptografado movido para: {processed_folder}\")\n",
    "\n",
    "    except pikepdf.PasswordError:\n",
    "        print(f\"O PDF '{pdf_files[0]}' está protegido por senha e não pode ser desbloqueado sem ela.\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Erro: Arquivo não encontrado. Verifique o caminho. {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro: {e}\")\n",
    "\n",
    "\n",
    "from PyPDF2 import PdfReader\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "# Paths das pastas\n",
    "input_folder = \"./maps/decrypted\"\n",
    "processed_folder = \"maps/decrypted/processed\"\n",
    "\n",
    "# Verificar se a pasta de processados existe, caso contrário, criá-la\n",
    "os.makedirs(processed_folder, exist_ok=True)\n",
    "\n",
    "# Obter a lista de PDFs na pasta de entrada\n",
    "pdf_files = [file for file in os.listdir(input_folder) if file.lower().endswith(\".pdf\")]\n",
    "\n",
    "if pdf_files:\n",
    "    # Processar cada PDF na pasta\n",
    "    for file_name in pdf_files:\n",
    "        input_pdf_path = os.path.join(input_folder, file_name)\n",
    "        processed_pdf_path = os.path.join(processed_folder, file_name)\n",
    "        \n",
    "        try:\n",
    "            # Inicializar o texto completo para o PDF atual\n",
    "            full_text = \"\"\n",
    "            \n",
    "            # Ler o PDF\n",
    "            reader = PdfReader(input_pdf_path)\n",
    "            \n",
    "            # Iterar sobre as páginas e adicionar os delimitadores\n",
    "            for idx, page in enumerate(reader.pages):\n",
    "                full_text += f\"------------------ PAGINA {idx} ----------------\\n\"\n",
    "                full_text += page.extract_text()\n",
    "            \n",
    "            # Dividir o texto baseado nos delimitadores\n",
    "            paginas = re.split(r\"------------------ PAGINA \\d+ ----------------\", full_text)\n",
    "            paginas = [pagina.strip() for pagina in paginas if pagina.strip()]\n",
    "            \n",
    "            # Exibir a quantidade de páginas úteis detectadas\n",
    "            print(f\"\\nTotal de páginas detectadas em '{file_name}': {len(paginas)}\\n\")\n",
    "            \n",
    "            # Criar dicionário para armazenar o conteúdo das páginas\n",
    "            texto_paginas = {}\n",
    "            for idx, pagina in enumerate(paginas, start=1):\n",
    "                texto_paginas[f\"texto_pagina{idx}\"] = pagina\n",
    "            \n",
    "            # Você pode processar o dicionário `texto_paginas` aqui, se necessário\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Ocorreu um erro ao processar '{file_name}': {e}\")\n",
    "        finally:\n",
    "            # Mover o PDF processado para a pasta de processados\n",
    "            shutil.move(input_pdf_path, processed_pdf_path)\n",
    "            print(f\"PDF '{file_name}' movido para a pasta de processados: {processed_pdf_path}\")\n",
    "else:\n",
    "    print(\"Nenhum PDF encontrado na pasta de entrada.\")\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Regexes para capturar os elementos de interesse\n",
    "regexes = {\n",
    "    'nome': re.compile(r'Nome:\\s+(.+)', re.MULTILINE),\n",
    "    'nif': re.compile(r'Nº de Identificação:\\s+(\\d+)'),\n",
    "    'mes_mapa': re.compile(r'Responsabilidades de crédito referentes a\\s+(.+)'),\n",
    "    'instituicao': re.compile(r'Informação comunicada pela instituição:\\s+(.+)'),\n",
    "    'total_em_divida': re.compile(r\"Montantes\\s+Total em dívida\\s+do qual, em incumprimento\\s+([\\d\\s,]+) €\"),\n",
    "    'litigio': re.compile(r'Em litígio judicial\\s+(Sim|Não)'),\n",
    "    'abatido_ativo': re.compile(r'Abatido ao ativo\\s+([\\d\\s,.]+) €'),\n",
    "    'garantias': re.compile(r\"Tipo\\s+Valor\\s+Número\\s+\\d+\\s+([\\d\\s,.]+) €\"),\n",
    "    'num_devedores': re.compile(r\"Nº devedores no contrato\\s+(\\d+)\"),\n",
    "    'prod_financeiro': re.compile(r\"Produto financeiro\\s+(.+?)\\s+Tipo de responsabilidade\"),\n",
    "    'dat_inicio': re.compile(r\"Início\\s+(\\d{4}-\\d{2}-\\d{2})\"),\n",
    "    'dat_fim': re.compile(r\"Fim\\s+(\\d{4}-\\d{2}-\\d{2})\\s+Em litígio judicial\"),\n",
    "    'entrada_incumpr': re.compile(r\"Entrada incumpr\\.\\s+(\\d{4}-\\d{2}-\\d{2})\\s+Tipo\")\n",
    "}\n",
    "\n",
    "# Função para aplicar regex em texto\n",
    "def get_feature(text, regex_string):\n",
    "    match = regexes[regex_string].search(text)\n",
    "    return match.group(1).strip() if match else None\n",
    " \n",
    "# Inicializar lista para armazenar os dados\n",
    "data = []\n",
    "\n",
    "# Iterar sobre as páginas do dicionário texto_paginas\n",
    "for page_number, page_text in texto_paginas.items():\n",
    "    # Extrair informações de cada página usando regex\n",
    "    row = {\n",
    "        'pagina_pdf': page_number,\n",
    "        'nome': get_feature(page_text, 'nome'),\n",
    "        'nif': get_feature(page_text, 'nif'),\n",
    "        'mes_mapa': get_feature(page_text, 'mes_mapa'),\n",
    "        'instituicao': get_feature(page_text, 'instituicao'),\n",
    "        'divida': get_feature(page_text, 'total_em_divida'),\n",
    "        'litigio': get_feature(page_text, 'litigio'),\n",
    "        'parcela': get_feature(page_text, 'abatido_ativo'),\n",
    "        'garantias': get_feature(page_text, 'garantias'),\n",
    "        'num_devedores': get_feature(page_text, 'num_devedores'),\n",
    "        'prod_financeiro': get_feature(page_text, 'prod_financeiro'),\n",
    "        'entrada_incumpr': get_feature(page_text,'entrada_incumpr'),\n",
    "        'dat_inicio': get_feature(page_text, 'dat_inicio'),\n",
    "        'dat_fim': get_feature(page_text, 'dat_fim')\n",
    "    }\n",
    "    # Adicionar os dados ao conjunto\n",
    "    data.append(row)\n",
    "\n",
    "# Criar o DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df.iloc[:-1]\n",
    "\n",
    "df\n",
    "\n",
    "#### TRATAMENTO DE DADOS DO SENNINHA\n",
    "\n",
    "# Tratamento da coluna divida\n",
    "df['divida'] = df['divida'].astype(str)  # Converte para string\n",
    "df['divida'] = df['divida'].str.replace(' ', '').str.replace(',', '.')  # Remove caracteres indesejados e ajusta separadores\n",
    "df['divida'] = pd.to_numeric(df['divida'], errors='coerce')  # Converte para numérico, substituindo erros por NaN\n",
    "df['divida'] = df['divida'].fillna(0.0)  # Substitui NaN por 0.0\n",
    "\n",
    "# Tratamento da coluna parcela\n",
    "df['parcela'] = df['parcela'].astype(str)  # Converte para string\n",
    "df['parcela'] = df['parcela'].str.replace(' ', '').str.replace(',', '.')  # Remove caracteres indesejados e ajusta separadores\n",
    "df['parcela'] = pd.to_numeric(df['parcela'], errors='coerce')  # Converte para numérico, substituindo erros por NaN\n",
    "df['parcela'] = df['parcela'].fillna(0.0)  # Substitui NaN por 0.0\n",
    "\n",
    "# Tratamento da coluna garantias\n",
    "df['garantias'] = df['garantias'].astype(str)  # Converte para string\n",
    "df['garantias'] = df['garantias'].str.replace(' ', '').str.replace(',', '.')  # Remove caracteres indesejados e ajusta separadores\n",
    "df['garantias'] = pd.to_numeric(df['garantias'], errors='coerce')  # Converte para numérico, substituindo erros por NaN\n",
    "df['garantias'] = df['garantias'].fillna(0.0)  # Substitui NaN por 0.0\n",
    "\n",
    "df\n",
    "\n",
    "#PERFILADOR SENNINHA\n",
    "\n",
    "# Aplicando o segundo filtro onde a coluna \"litigio\" é igual a \"Não\"\n",
    "df_litigio= df[df[\"litigio\"] == \"Não\"]\n",
    "\n",
    "# Lista de opções para filtro\n",
    "opcoes_prod_financeiro = [\n",
    "    \"Cartão de crédito - sem período de free-float\",\n",
    "    \"Cartão de crédito - com período de free-float\",\n",
    "    \"Crédito automóvel (excluíndo locações financeiras)\",\n",
    "    \"Crédito pessoal\",\n",
    "    \"Crédito renovável - Linha de crédito\",\n",
    "    \"Cartão de crédito\",\n",
    "    \"Outros créditos\",\n",
    "    \"Ultrapassagens de crédito\",\n",
    "    \"Crédito renovável - conta corrente bancária\",\n",
    "    \"Facilidades de descoberto\",\n",
    "    \"Cartão de crédito - cartão de débito diferido\"\n",
    "]\n",
    "\n",
    "# Aplicando o primeiro filtro onde a coluna \"produtos financeiros\" é igual aos prod_financeiros que perfilam\n",
    "df_prod_fin = df_litigio[df_litigio[\"prod_financeiro\"].isin(opcoes_prod_financeiro)]\n",
    "\n",
    "# Aplicando o segundo filtro onde a coluna \"litigio\" é igual a \"Não\"\n",
    "df_prod_fin = df_prod_fin[df_prod_fin[\"litigio\"] == \"Não\"]\n",
    "\n",
    "# Aplicado o terceiro filtro onde a coluna \"garantias\" é menor ou igual a 0.0\n",
    "df_prod_fin = df_prod_fin[df_prod_fin[\"garantias\"] <= 0]\n",
    "\n",
    "\n",
    "df_perfilados_agg = (\n",
    "    df_prod_fin.groupby(\"nif\", as_index=False)\n",
    "    .agg({\n",
    "        \"nome\": \"first\",\n",
    "        \"mes_mapa\": \"first\",\n",
    "        \"litigio\": \"first\",\n",
    "        \"divida\": \"sum\",\n",
    "        \"garantias\": \"sum\"\n",
    "    })\n",
    ")\n",
    "\n",
    "df_perfilados_agg\n",
    "\n",
    "def controle_fluxo(df_perfilados_agg, processed_pdf_path):\n",
    "    \"\"\"\n",
    "    Verifica se o valor da coluna 'divida' em df_perfilados_agg (registro único) é maior ou igual a 6000.\n",
    "    Se for, copia o arquivo especificado em processed_pdf_path para o diretório de destino.\n",
    "\n",
    "    Args:\n",
    "        df_perfilados_agg (DataFrame): DataFrame contendo a coluna 'divida' com apenas um registro.\n",
    "        processed_pdf_path (str): Caminho completo do arquivo a ser copiado.\n",
    "    \"\"\"\n",
    "    # Diretório de destino\n",
    "    destination_dir = \"maps/f2_senninha\"\n",
    "\n",
    "    # Verifica se o destino existe, caso contrário, cria-o\n",
    "    if not os.path.exists(destination_dir):\n",
    "        os.makedirs(destination_dir)\n",
    "\n",
    "    # Verifica se o valor de 'divida' atende à condição\n",
    "    if df_perfilados_agg.loc[0, \"divida\"] >= 6000:\n",
    "        # Extrai o nome do arquivo do caminho fornecido\n",
    "        file_name = os.path.basename(processed_pdf_path)\n",
    "        destination_path = os.path.join(destination_dir, file_name)\n",
    "\n",
    "        # Verifica se o arquivo de origem existe e realiza a cópia\n",
    "        if os.path.exists(processed_pdf_path):\n",
    "            shutil.copy(processed_pdf_path, destination_path)\n",
    "            print(f\"Arquivo {file_name} copiado para {destination_dir}.\")\n",
    "        else:\n",
    "            print(f\"Arquivo {processed_pdf_path} não encontrado.\")\n",
    "    else:\n",
    "        print(\"A dívida é menor que 6000. Nenhuma ação realizada.\")\n",
    "\n",
    "\n",
    "controle_fluxo(df_perfilados_agg, processed_pdf_path)\n",
    "\n",
    "df_perfilados_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEVELOP PERFILADOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         nif                               nome         mes_mapa litigio  \\\n",
       " 0  271878061  FABIO JOSE ROSA DOS SANTOS CATITA  janeiro de 2024     Não   \n",
       " \n",
       "     divida  garantias  \n",
       " 0  4127.73        0.0  ,\n",
       " 'decrypted_09f6484e-1c43-472c-8f8d-9e4d69581026.pdf')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PERFILADOR SENNINHA \n",
    "\n",
    "# Aplicando o segundo filtro onde a coluna \"litigio\" é igual a \"Não\"\n",
    "df_litigio= df[df[\"litigio\"] == \"Não\"]\n",
    "\n",
    "# Lista de opções para filtro\n",
    "opcoes_prod_financeiro = [\n",
    "    \"Cartão de crédito - sem período de free-float\",\n",
    "    \"Cartão de crédito - com período de free-float\",\n",
    "    \"Crédito automóvel (excluíndo locações financeiras)\",\n",
    "    \"Crédito pessoal\",\n",
    "    \"Crédito renovável - Linha de crédito\",\n",
    "    \"Cartão de crédito\",\n",
    "    \"Outros créditos\",\n",
    "    \"Ultrapassagens de crédito\",\n",
    "    \"Crédito renovável - conta corrente bancária\",\n",
    "    \"Facilidades de descoberto\",\n",
    "    \"Cartão de crédito - cartão de débito diferido\"\n",
    "]\n",
    "\n",
    "# Aplicando o primeiro filtro onde a coluna \"produtos financeiros\" é igual aos prod_financeiros que perfilam\n",
    "df_prod_fin = df_litigio[df_litigio[\"prod_financeiro\"].isin(opcoes_prod_financeiro)]\n",
    "\n",
    "# Aplicando o segundo filtro onde a coluna \"litigio\" é igual a \"Não\"\n",
    "df_prod_fin = df_prod_fin[df_prod_fin[\"litigio\"] == \"Não\"]\n",
    "\n",
    "# Aplicado o terceiro filtro onde a coluna \"garantias\" é menor ou igual a 0.0\n",
    "df_prod_fin = df_prod_fin[df_prod_fin[\"garantias\"] <= 0]\n",
    "\n",
    "# somando dividas perfiladas\n",
    "df_perfilados_agg = (\n",
    "    df_prod_fin.groupby(\"nif\", as_index=False)\n",
    "    .agg({\n",
    "        \"nome\": \"first\",\n",
    "        \"mes_mapa\": \"first\",\n",
    "        \"litigio\": \"first\",\n",
    "        \"divida\": \"sum\",\n",
    "        \"garantias\": \"sum\"\n",
    "    })\n",
    ")\n",
    "\n",
    "df_perfilados_agg, file_name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
