{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./.venv/lib/python3.13/site-packages (from pandas) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.13/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.13/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: pypdf in ./.venv/lib/python3.13/site-packages (5.1.0)\n",
      "Requirement already satisfied: pypdf2 in ./.venv/lib/python3.13/site-packages (3.0.1)\n",
      "Requirement already satisfied: cryptography in ./.venv/lib/python3.13/site-packages (44.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in ./.venv/lib/python3.13/site-packages (from cryptography) (1.17.1)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.13/site-packages (from cffi>=1.12->cryptography) (2.22)\n",
      "Requirement already satisfied: pikepdf in ./.venv/lib/python3.13/site-packages (9.4.2)\n",
      "Requirement already satisfied: Pillow>=10.0.1 in ./.venv/lib/python3.13/site-packages (from pikepdf) (11.0.0)\n",
      "Requirement already satisfied: Deprecated in ./.venv/lib/python3.13/site-packages (from pikepdf) (1.2.15)\n",
      "Requirement already satisfied: lxml>=4.8 in ./.venv/lib/python3.13/site-packages (from pikepdf) (5.3.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.13/site-packages (from pikepdf) (24.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in ./.venv/lib/python3.13/site-packages (from Deprecated->pikepdf) (1.17.0)\n",
      "Collecting google-api-python-client\n",
      "  Downloading google_api_python_client-2.155.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-auth-httplib2\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth-oauthlib\n",
      "  Downloading google_auth_oauthlib-1.2.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 (from google-api-python-client)\n",
      "  Downloading google_auth-2.37.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 (from google-api-python-client)\n",
      "  Downloading google_api_core-2.24.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client)\n",
      "  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in ./.venv/lib/python3.13/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (5.29.1)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client)\n",
      "  Downloading proto_plus-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in ./.venv/lib/python3.13/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.venv/lib/python3.13/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (5.5.0)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client)\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2<1.dev0,>=0.19.0->google-api-python-client)\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2024.12.14)\n",
      "Downloading google_api_python_client-2.155.0-py2.py3-none-any.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading google_auth_oauthlib-1.2.1-py2.py3-none-any.whl (24 kB)\n",
      "Downloading google_api_core-2.24.0-py3-none-any.whl (158 kB)\n",
      "Downloading google_auth-2.37.0-py2.py3-none-any.whl (209 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading proto_plus-1.25.0-py3-none-any.whl (50 kB)\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Downloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: uritemplate, pyparsing, pyasn1, proto-plus, oauthlib, googleapis-common-protos, rsa, requests-oauthlib, pyasn1-modules, httplib2, google-auth, google-auth-oauthlib, google-auth-httplib2, google-api-core, google-api-python-client\n",
      "Successfully installed google-api-core-2.24.0 google-api-python-client-2.155.0 google-auth-2.37.0 google-auth-httplib2-0.2.0 google-auth-oauthlib-1.2.1 googleapis-common-protos-1.66.0 httplib2-0.22.0 oauthlib-3.2.2 proto-plus-1.25.0 pyasn1-0.6.1 pyasn1-modules-0.4.1 pyparsing-3.2.0 requests-oauthlib-2.0.0 rsa-4.9 uritemplate-4.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install pypdf\n",
    "!pip install pypdf2\n",
    "!pip install cryptography\n",
    "!pip install pikepdf\n",
    "!pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasta criada: ./maps/encrypted/\n",
      "Pasta criada: ./maps/encrypted/processed\n",
      "Pasta criada: ./maps/decrypted/\n",
      "Pasta criada: ./maps/decrypted/processed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pikepdf\n",
    "\n",
    "# Caminhos das pastas\n",
    "source_folder = \"./maps/encrypted/\"\n",
    "processed_folder = os.path.join(source_folder, \"processed\")\n",
    "decrypted_folder = \"./maps/decrypted/\"\n",
    "decrypted_processed_folder = os.path.join(decrypted_folder, \"processed\")\n",
    "\n",
    "# Função para verificar e criar a hierarquia de pastas\n",
    "def ensure_folders_exist():\n",
    "    folders = [source_folder, processed_folder, decrypted_folder, decrypted_processed_folder]\n",
    "    for folder in folders:\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "            print(f\"Pasta criada: {folder}\")\n",
    "        else:\n",
    "            print(f\"Pasta já existe: {folder}\")\n",
    "\n",
    "# Cria a hierarquia de pastas\n",
    "ensure_folders_exist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nenhum arquivo PDF encontrado na pasta maps.\n"
     ]
    }
   ],
   "source": [
    "# Busca o primeiro arquivo PDF na pasta maps\n",
    "pdf_files = [f for f in os.listdir(source_folder) if f.endswith('.pdf')]\n",
    "\n",
    "if not pdf_files:\n",
    "    print(\"Nenhum arquivo PDF encontrado na pasta maps.\")\n",
    "else:\n",
    "    encrypted_pdf_path = os.path.join(source_folder, pdf_files[0])\n",
    "    decrypted_pdf_path = os.path.join(decrypted_folder, f\"decrypted_{pdf_files[0]}\")\n",
    "\n",
    "    try:\n",
    "        # Tenta descriptografar o PDF\n",
    "        with pikepdf.open(encrypted_pdf_path) as pdf:\n",
    "            pdf.save(decrypted_pdf_path)\n",
    "        print(f\"PDF desbloqueado com sucesso! Salvo em: {decrypted_pdf_path}\")\n",
    "\n",
    "        # Move o PDF criptografado para a pasta processed\n",
    "        shutil.move(encrypted_pdf_path, os.path.join(processed_folder, pdf_files[0]))\n",
    "        print(f\"PDF original criptografado movido para: {processed_folder}\")\n",
    "\n",
    "    except pikepdf.PasswordError:\n",
    "        print(f\"O PDF '{pdf_files[0]}' está protegido por senha e não pode ser desbloqueado sem ela.\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Erro: Arquivo não encontrado. Verifique o caminho. {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total de páginas detectadas em 'decrypted_inbound4889561322967299113.pdf': 4\n",
      "\n",
      "PDF 'decrypted_inbound4889561322967299113.pdf' movido para a pasta de processados: maps/decrypted/processed/decrypted_inbound4889561322967299113.pdf\n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "# Paths das pastas\n",
    "input_folder = \"./maps/decrypted\"\n",
    "processed_folder = \"maps/decrypted/processed\"\n",
    "\n",
    "# Verificar se a pasta de processados existe, caso contrário, criá-la\n",
    "os.makedirs(processed_folder, exist_ok=True)\n",
    "\n",
    "# Obter a lista de PDFs na pasta de entrada\n",
    "pdf_files = [file for file in os.listdir(input_folder) if file.lower().endswith(\".pdf\")]\n",
    "\n",
    "if pdf_files:\n",
    "    # Processar cada PDF na pasta\n",
    "    for file_name in pdf_files:\n",
    "        input_pdf_path = os.path.join(input_folder, file_name)\n",
    "        processed_pdf_path = os.path.join(processed_folder, file_name)\n",
    "        \n",
    "        try:\n",
    "            # Inicializar o texto completo para o PDF atual\n",
    "            full_text = \"\"\n",
    "            \n",
    "            # Ler o PDF\n",
    "            reader = PdfReader(input_pdf_path)\n",
    "            \n",
    "            # Iterar sobre as páginas e adicionar os delimitadores\n",
    "            for idx, page in enumerate(reader.pages):\n",
    "                full_text += f\"------------------ PAGINA {idx} ----------------\\n\"\n",
    "                full_text += page.extract_text()\n",
    "            \n",
    "            # Dividir o texto baseado nos delimitadores\n",
    "            paginas = re.split(r\"------------------ PAGINA \\d+ ----------------\", full_text)\n",
    "            paginas = [pagina.strip() for pagina in paginas if pagina.strip()]\n",
    "            \n",
    "            # Exibir a quantidade de páginas úteis detectadas\n",
    "            print(f\"\\nTotal de páginas detectadas em '{file_name}': {len(paginas)}\\n\")\n",
    "            \n",
    "            # Criar dicionário para armazenar o conteúdo das páginas\n",
    "            texto_paginas = {}\n",
    "            for idx, pagina in enumerate(paginas, start=1):\n",
    "                texto_paginas[f\"texto_pagina{idx}\"] = pagina\n",
    "            \n",
    "            # Você pode processar o dicionário `texto_paginas` aqui, se necessário\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Ocorreu um erro ao processar '{file_name}': {e}\")\n",
    "        finally:\n",
    "            # Mover o PDF processado para a pasta de processados\n",
    "            shutil.move(input_pdf_path, processed_pdf_path)\n",
    "            print(f\"PDF '{file_name}' movido para a pasta de processados: {processed_pdf_path}\")\n",
    "else:\n",
    "    print(\"Nenhum PDF encontrado na pasta de entrada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pagina_pdf</th>\n",
       "      <th>nome</th>\n",
       "      <th>nif</th>\n",
       "      <th>mes_mapa</th>\n",
       "      <th>instituicao</th>\n",
       "      <th>divida</th>\n",
       "      <th>litigio</th>\n",
       "      <th>parcela</th>\n",
       "      <th>garantias</th>\n",
       "      <th>num_devedores</th>\n",
       "      <th>prod_financeiro</th>\n",
       "      <th>entrada_incumpr</th>\n",
       "      <th>dat_inicio</th>\n",
       "      <th>dat_fim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>texto_pagina1</td>\n",
       "      <td>MARIA ISABEL DOS SANTOS OLIVEIRA PASSOS</td>\n",
       "      <td>150590075</td>\n",
       "      <td>outubro de 2024</td>\n",
       "      <td>BNP PARIBAS PERSONAL FINANCE, S.A. - SUCURSAL ...</td>\n",
       "      <td>387,07</td>\n",
       "      <td>Não</td>\n",
       "      <td>0,00</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Cartão de crédito - com período de free-float</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>2018-12-18</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>texto_pagina2</td>\n",
       "      <td>MARIA ISABEL DOS SANTOS OLIVEIRA PASSOS</td>\n",
       "      <td>150590075</td>\n",
       "      <td>outubro de 2024</td>\n",
       "      <td>BANCO COMERCIAL PORTUGUÊS, SA (0033)</td>\n",
       "      <td>19 117,34</td>\n",
       "      <td>Não</td>\n",
       "      <td>158,89</td>\n",
       "      <td>106 500,00</td>\n",
       "      <td>1</td>\n",
       "      <td>Crédito pessoal</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-10-07</td>\n",
       "      <td>2035-10-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>texto_pagina3</td>\n",
       "      <td>MARIA ISABEL DOS SANTOS OLIVEIRA PASSOS</td>\n",
       "      <td>150590075</td>\n",
       "      <td>outubro de 2024</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pagina_pdf                                     nome        nif  \\\n",
       "0  texto_pagina1  MARIA ISABEL DOS SANTOS OLIVEIRA PASSOS  150590075   \n",
       "1  texto_pagina2  MARIA ISABEL DOS SANTOS OLIVEIRA PASSOS  150590075   \n",
       "2  texto_pagina3  MARIA ISABEL DOS SANTOS OLIVEIRA PASSOS  150590075   \n",
       "\n",
       "          mes_mapa                                        instituicao  \\\n",
       "0  outubro de 2024  BNP PARIBAS PERSONAL FINANCE, S.A. - SUCURSAL ...   \n",
       "1  outubro de 2024               BANCO COMERCIAL PORTUGUÊS, SA (0033)   \n",
       "2  outubro de 2024                                               None   \n",
       "\n",
       "      divida litigio parcela   garantias num_devedores  \\\n",
       "0     387,07     Não    0,00        None             1   \n",
       "1  19 117,34     Não  158,89  106 500,00             1   \n",
       "2       None    None    None        None          None   \n",
       "\n",
       "                                 prod_financeiro entrada_incumpr  dat_inicio  \\\n",
       "0  Cartão de crédito - com período de free-float      2023-07-01  2018-12-18   \n",
       "1                                Crédito pessoal            None  2020-10-07   \n",
       "2                                           None            None        None   \n",
       "\n",
       "      dat_fim  \n",
       "0  9999-12-31  \n",
       "1  2035-10-08  \n",
       "2        None  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Regexes para capturar os elementos de interesse\n",
    "regexes = {\n",
    "    'nome': re.compile(r'Nome:\\s+(.+)', re.MULTILINE),\n",
    "    'nif': re.compile(r'Nº de Identificação:\\s+(\\d+)'),\n",
    "    'mes_mapa': re.compile(r'Responsabilidades de crédito referentes a\\s+(.+)'),\n",
    "    'instituicao': re.compile(r'Informação comunicada pela instituição:\\s+(.+)'),\n",
    "    'total_em_divida': re.compile(r\"Montantes\\s+Total em dívida\\s+do qual, em incumprimento\\s+([\\d\\s,]+) €\"),\n",
    "    'litigio': re.compile(r'Em litígio judicial\\s+(Sim|Não)'),\n",
    "    'abatido_ativo': re.compile(r'Abatido ao ativo\\s+([\\d\\s,.]+) €'),\n",
    "    'garantias': re.compile(r\"Tipo\\s+Valor\\s+Número\\s+\\d+\\s+([\\d\\s,.]+) €\"),\n",
    "    'num_devedores': re.compile(r\"Nº devedores no contrato\\s+(\\d+)\"),\n",
    "    'prod_financeiro': re.compile(r\"Produto financeiro\\s+(.+?)\\s+Tipo de responsabilidade\"),\n",
    "    'dat_inicio': re.compile(r\"Início\\s+(\\d{4}-\\d{2}-\\d{2})\"),\n",
    "    'dat_fim': re.compile(r\"Fim\\s+(\\d{4}-\\d{2}-\\d{2})\\s+Em litígio judicial\"),\n",
    "    'entrada_incumpr': re.compile(r\"Entrada incumpr\\.\\s+(\\d{4}-\\d{2}-\\d{2})\\s+Tipo\")\n",
    "}\n",
    "\n",
    "# Função para aplicar regex em texto\n",
    "def get_feature(text, regex_string):\n",
    "    match = regexes[regex_string].search(text)\n",
    "    return match.group(1).strip() if match else None\n",
    " \n",
    "# Inicializar lista para armazenar os dados\n",
    "data = []\n",
    "\n",
    "# Iterar sobre as páginas do dicionário texto_paginas\n",
    "for page_number, page_text in texto_paginas.items():\n",
    "    # Extrair informações de cada página usando regex\n",
    "    row = {\n",
    "        'pagina_pdf': page_number,\n",
    "        'nome': get_feature(page_text, 'nome'),\n",
    "        'nif': get_feature(page_text, 'nif'),\n",
    "        'mes_mapa': get_feature(page_text, 'mes_mapa'),\n",
    "        'instituicao': get_feature(page_text, 'instituicao'),\n",
    "        'divida': get_feature(page_text, 'total_em_divida'),\n",
    "        'litigio': get_feature(page_text, 'litigio'),\n",
    "        'parcela': get_feature(page_text, 'abatido_ativo'),\n",
    "        'garantias': get_feature(page_text, 'garantias'),\n",
    "        'num_devedores': get_feature(page_text, 'num_devedores'),\n",
    "        'prod_financeiro': get_feature(page_text, 'prod_financeiro'),\n",
    "        'entrada_incumpr': get_feature(page_text,'entrada_incumpr'),\n",
    "        'dat_inicio': get_feature(page_text, 'dat_inicio'),\n",
    "        'dat_fim': get_feature(page_text, 'dat_fim')\n",
    "    }\n",
    "    # Adicionar os dados ao conjunto\n",
    "    data.append(row)\n",
    "\n",
    "# Criar o DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df.iloc[:-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
